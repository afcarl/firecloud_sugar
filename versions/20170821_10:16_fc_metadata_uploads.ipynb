{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Firecloud: Uploading Metadata to Firecloud\n",
    "Mimoun Cadosch 7/17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from firecloud import api as firecloud_api\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "## Resources\n",
    "# https://github.com/broadinstitute/fiss/blob/master/firecloud/api.py\n",
    "# https://github.com/broadinstitute/firecloud-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "namespace = \"nci-mimoun-bi-org\"\n",
    "workspace = \"CCLF_TSCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def delete_sample(namespace, workspace, sample_id):\n",
    "    \"\"\"Delete sample from workspace/namespace\n",
    "    Args: \n",
    "        Self-explanatory\n",
    "    Returns: \n",
    "        HTTP Response\n",
    "    \"\"\"\n",
    "    body = [{\"entityType\": \"sample\", \"entityName\": sample_id}]\n",
    "    res = firecloud_api.delete_entities(namespace, workspace, body)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_sample_set(namespace, workspace, sample_set_id):\n",
    "    \"\"\"Delete sample set from workspace/namespace\n",
    "    Args: \n",
    "        Self-explanatory\n",
    "    Returns: \n",
    "        HTTP Response\n",
    "    \"\"\"\n",
    "    body = [{\"entityType\": \"sample_set\", \"entityName\": sample_set_id}]\n",
    "    res = firecloud_api.delete_entities(namespace, workspace, body)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_workspace_config(namespace, workspace, cnamespace, config):\n",
    "    \"\"\"Delete workspace configuration\n",
    "    Args: \n",
    "        Self-explanatory\n",
    "    Returns: \n",
    "        HTTP Response\n",
    "    \"\"\"\n",
    "    res = firecloud_api.delete_workspace_config(namespace, workspace, cnamespace, config)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def upload_entities_from_tsv(namespace, workspace, entities_tsv_file):\n",
    "    \"\"\"Upload entities from tsv file\n",
    "    Args: \n",
    "        Self-explanatory\n",
    "        entities_tsv_file: path to tsv file\n",
    "    Returns: \n",
    "        HTTP Response\n",
    "    \"\"\"\n",
    "    res = firecloud_api.upload_entities_tsv(namespace, workspace, entities_tsv=entities_tsv_file)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# res = firecloud_api.delete_workspace_config(namespace, workspace, \"tsca\", \"Mutect2TumorOnly\")\n",
    "# res = firecloud_api.delete_workspace_config(namespace, workspace, 'tsca', 'CreatePanelOfNormalsGATK')\n",
    "# delete_sample(namespace, workspace, \"AA66-Tumor-SM-F29RQ\")\n",
    "# delete_sample_set(namespace, workspace, sample_set_id='TSCA20_new')\n",
    "# firecloud_api.delete_repository_method('tsca', 'Mutect2TumorOnly', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def patients_for_metadata_import(path, tsca_id):\n",
    "    \"\"\"Create participant entities in Firecloud. \n",
    "    Patients need to exist before you can upload their respective samples\n",
    "    Args:\n",
    "        path_id: path to file ending in {}.import_samples.txt\n",
    "        tsca_id: tsca id\n",
    "    Pending:\n",
    "        Are we allowed to add age, gender, race?\n",
    "    Saves: \n",
    "        ./tsca_id/fc_upload_patients_tsca_{tsca_id}.csv:\n",
    "            contains patient ids in tsca batch\n",
    "    \"\"\"    \n",
    "    raw = pd.read_table(path)\n",
    "    print( \"%d Participants in this batch\" % raw['individual_id'].unique().shape[0] )\n",
    "    # Data to upload\n",
    "    data = pd.DataFrame(raw.individual_id.drop_duplicates()).rename(columns={'individual_id':'entity:participant_id'})\n",
    "    os.system('mkdir -p %s'%tsca_id)\n",
    "    filename = './%s/fc_upload_patients_tsca_%s.txt' % (tsca_id, tsca_id)\n",
    "    data.to_csv(filename, '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_sample_set_for_metadata_import(path, tsca_id):\n",
    "    \"\"\"Create sample_set entities in Firecloud.\n",
    "    A sample for a given batch \n",
    "    Args:\n",
    "        path: path to file ending in {}.import_samples.txt\n",
    "        tsca_id: batch tsca id\n",
    "    \"\"\"\n",
    "    raw = pd.read_table(path)\n",
    "    print( \"%d Samples in this batch\" % raw.shape[0] )\n",
    "\n",
    "    # Data to upload\n",
    "    data = pd.concat([pd.DataFrame(index=raw.index, columns=['membership:sample_set_id'], data=tsca_id), \\\n",
    "                      raw.sample_id], axis=1)\n",
    "    os.system('mkdir -p %s'%tsca_id)\n",
    "    filename = './%s/fc_upload_sample_set_tsca_%s.txt' % (tsca_id, tsca_id)\n",
    "    data.to_csv(filename, '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def batch_samples_for_metadata_import(path, tsca_id, google_bucket_id):\n",
    "    \"\"\"Prepare the file to import samples metadata to firecloud\n",
    "    Args:\n",
    "        path_id: path to file ending in {}.import_samples.txt\n",
    "        tsca_id: TSCAXX\n",
    "        google_bucket_id: id of google bucket ('gs://google_bucket_id')\n",
    "    Returns:\n",
    "        pd.DF of data ready for import\n",
    "    Saves:\n",
    "        ./{tsca_id}/fc_upload_samples_tsca_{tsca_id}.txt\n",
    "    \"\"\"\n",
    "    # Import raw data\n",
    "    data = pd.read_table(path)\n",
    "    \n",
    "    # Rename columns to match firecloud requirements\n",
    "    data = data.rename(columns={'sample_id':'entity:sample_id', 'individual_id':'participant_id'})\n",
    "    \n",
    "    # Locations of BAM files in google bucket\n",
    "    path_in_bucket_full = \"gs://%s/seq_data/%s\" % (google_bucket_id, tsca_id)\n",
    "\n",
    "    # Extract bam filename\n",
    "    data['bam_filename'] = data.apply(lambda row: row['clean_bam_file_capture'].split('/')[-1], axis=1)\n",
    "    \n",
    "    # Create bai filename (change extension on .bam file)\n",
    "    data['bai_filename'] = data.apply(lambda row: \"%s%s\" %(row['bam_filename'][:-3], 'bai'), axis=1)\n",
    "    \n",
    "    # Change BAM path from xchip to Google cloud\n",
    "    data['clean_bam_file_capture'] = \\\n",
    "        data.apply( lambda row: \"%s/%s/%s\" \\\n",
    "                   %(path_in_bucket_full, row['external_id_validation'], row['bam_filename']), axis=1)\n",
    "    \n",
    "    # Add location of .bai file \n",
    "    data['clean_bai_file_capture'] = \\\n",
    "        data.apply( lambda row: \"%s/%s/%s\" \\\n",
    "                   %(path_in_bucket_full, row['external_id_validation'], row['bai_filename']), axis=1)\n",
    "       \n",
    "    # Add TSCA ID\n",
    "    data['tsca_id'] = tsca_id\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def panel_of_normals_for_metadata_import(paths, N, name):\n",
    "    \"\"\"Create panel of normals sample set for Firecloud from multiple TSCA batches\n",
    "    Args:\n",
    "        paths: (list) paths to file ending in {}.import_samples.txt\n",
    "        tsca_id: (string) batch tsca id\n",
    "        N: (int) number of samples in panel of normals\n",
    "        name: (string) name of Panel of Normals\n",
    "    \"\"\"\n",
    "    \n",
    "    df0 = pd.read_table(paths[0])\n",
    "    dfs = [df0]\n",
    "    for path in paths[1:]:\n",
    "        df_to_concat = pd.read_table(path)\n",
    "        dfs.append(df_to_concat)\n",
    "\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    normals = df[df.sample_type==\"Normal\"][:N]['sample_id']\n",
    "    if N==-1: print (\"Creating panel of %d normals\" %normals.shape[0])\n",
    "    else: print (\"Creating panel of %d normals\" %N)\n",
    "    \n",
    "    data = pd.concat([pd.DataFrame(index=normals.index, columns=['membership:sample_set_id'], data=name), \\\n",
    "                        normals], axis=1)\n",
    "\n",
    "    os.system('mkdir -p PoNs')\n",
    "    filename = './PoNs/fc_upload_PoN_sample_set_tsca_%s.txt' % (name)\n",
    "    data.to_csv(filename, '\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_df_to_csv(data, tsca_id):\n",
    "    data.to_csv('%s/fc_upload_samples_tsca_%s.txt' % (tsca_id, tsca_id), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_samples(paths_to_samples_info, google_bucket_id):\n",
    "    \"\"\"Compile all samples from all batches\n",
    "    Args: Self-explanatory\n",
    "        - paths_to_samples_info: .xlsx file containing paths to files containing sample_info\n",
    "    Returns: \n",
    "        - df with samples from all batches\n",
    "    \"\"\"\n",
    "    paths_to_samples_info = pd.read_excel(paths_to_samples_info, index_col=0)\n",
    "    df_list = []\n",
    "\n",
    "    for tsca_id, paths in paths_to_samples_info.iterrows():\n",
    "        # Make data Firecloud-compatible\n",
    "        batch_data = batch_samples_for_metadata_import(paths.path_to_samples_info, tsca_id, google_bucket_id)\n",
    "        df_list.append(batch_data)\n",
    "\n",
    "    all_samples = pd.concat(df_list, axis=0)\n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_matching_samples(all_samples, batch_samples):\n",
    "    \"\"\"Add sample_id and bam filepath of matching normals and primary tumor tissue for every sample\n",
    "    Args:\n",
    "        - all_samples: df with target samples we want to find matches in\n",
    "        - batch_samples: df with source samples we want to find matches for\n",
    "    Returns: \n",
    "        - batch_samples (augmented)\n",
    "    \"\"\"\n",
    "    for index, row in batch_samples.iterrows():\n",
    "        # Find all samples from same individual (same individual_id, different sample_id)\n",
    "        patient_samples = all_samples[ (all_samples['participant_id'] == row['participant_id']) \\\n",
    "                                      & (all_samples['entity:sample_id'] != row['entity:sample_id']) ]\n",
    "\n",
    "        # NOTE: If more than one match tumor tissue or match normal found, select one at random.\n",
    "        # The match normal is used to compute allelic fractions in Mutect2, so for now we ignore the conditions it was grown in.\n",
    "\n",
    "        # Tumor tissue: Add primary tumor tissue\n",
    "        match_primary_tumor = patient_samples[ patient_samples['external_id_validation'] \\\n",
    "                                              .str.contains('primary|prim|tissue|tiss') ]\n",
    "        #    > No primary tumor tissue found\n",
    "        if match_primary_tumor.empty:\n",
    "            batch_samples.loc[index, 'match_primary_tumor_sample_id'] = \"NA\"\n",
    "            batch_samples.loc[index, 'match_primary_tumor_bam_file'] = \"NA\"\n",
    "        #    > Tumor tissue found\n",
    "        elif match_primary_tumor.shape[0] > 0:\n",
    "            import pdb; pdb.set_trace()\n",
    "            match_primary_tumor.sample(n=1)\n",
    "            batch_samples.loc[index, 'match_primary_tumor_sample_id'] = match_primary_tumor['entity:sample_id'].item()\n",
    "            batch_samples.loc[index, 'match_primary_tumor_bam_file'] = match_primary_tumor['clean_bam_file_capture'].item()\n",
    "\n",
    "        # Add match normal\n",
    "        match_normal = patient_samples[ patient_samples['sample_type'] == \"Normal\"]\n",
    "        #   > No match normal found\n",
    "        if match_normal.empty: \n",
    "            batch_samples.loc[index, 'match_normal_sample_id'] = \"NA\"\n",
    "            batch_samples.loc[index, 'match_normal_bam_file'] = \"NA\"\n",
    "        #   > Match normal found\n",
    "        elif match_normal.shape[0] > 0:\n",
    "            match_normal = match_normal.sample(n=1)\n",
    "            batch_samples.loc[index, 'match_normal_sample_id'] = match_normal['entity:sample_id'].item()\n",
    "            batch_samples.loc[index, 'match_normal_bam_file'] = match_normal['clean_bam_file_capture'].item()\n",
    "            \n",
    "    return batch_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paths_to_samples_info = pd.read_excel('paths_to_samples_info.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/xchip/clf/seq_data/processed_for_fh/tsca18_201704_SN0119223/tsca18_201704_SN0119223.import_samples.txt'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths_to_samples_info.loc[4, 'path_to_samples_info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [],
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 Participants in this batch\n",
      "95 Samples in this batch\n",
      "> <ipython-input-48-c4df0196f451>(25)add_matching_samples()\n",
      "-> match_primary_tumor.sample(n=1)\n",
      "(Pdb) match_primary_tumor.shape\n",
      "(1, 18)\n",
      "(Pdb) match_primary_tumor\n",
      "        entity:sample_id participant_id  \\\n",
      "5  BT1009-Tumor-SM-DB2HZ         BT1009   \n",
      "\n",
      "                              clean_bam_file_capture external_id_validation  \\\n",
      "5  gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...         BT1009_primary   \n",
      "\n",
      "    aggregation_product_name_validation bsp_sample_id_validation  \\\n",
      "5  TSCA Rapid Cancer Detection Panel v2                 SM-DB9J7   \n",
      "\n",
      "  stock_sample_id_validation sample_type picard_aggregation_type_validation  \\\n",
      "5                   SM-DB2HZ       Tumor                                PCR   \n",
      "\n",
      "      processed_subtype_validation source_subtype_validation  \\\n",
      "5  Tissue:Tissue Lysate/Homogenate       Tissue:Fresh Tissue   \n",
      "\n",
      "  squid_sample_id_validation tumor_subtype short_letter_code  \\\n",
      "5             BT1009_primary    Metastatic                TM   \n",
      "\n",
      "                                        bam_filename  \\\n",
      "5  1_BT1009_primary_HYTLGBCXX.1.aligned.duplicate...   \n",
      "\n",
      "                                        bai_filename  \\\n",
      "5  1_BT1009_primary_HYTLGBCXX.1.aligned.duplicate...   \n",
      "\n",
      "                              clean_bai_file_capture tsca_id  \n",
      "5  gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...  TSCA14  \n",
      "(Pdb) index\n",
      "6\n",
      "(Pdb) row\n",
      "entity:sample_id                                                   BT1009-Tumor-SM-EUVFS\n",
      "participant_id                                                                    BT1009\n",
      "clean_bam_file_capture                 gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...\n",
      "external_id_validation                                                     BT1009_NSA_p5\n",
      "aggregation_product_name_validation                 TSCA Rapid Cancer Detection Panel v2\n",
      "bsp_sample_id_validation                                                        SM-EUVFS\n",
      "stock_sample_id_validation                                                      SM-EUS9R\n",
      "sample_type                                                                        Tumor\n",
      "picard_aggregation_type_validation                                                   PCR\n",
      "processed_subtype_validation                                             DNA:DNA Somatic\n",
      "source_subtype_validation                                                  Cells:Growing\n",
      "squid_sample_id_validation                                                 BT1009_NSA_p5\n",
      "tumor_subtype                                                                 Metastatic\n",
      "short_letter_code                                                                     TM\n",
      "bam_filename                           2_BT1009_NSA_p5_HFVFGBCXY.2.aligned.duplicates...\n",
      "bai_filename                           2_BT1009_NSA_p5_HFVFGBCXY.2.aligned.duplicates...\n",
      "clean_bai_file_capture                 gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...\n",
      "tsca_id                                                                           TSCA18\n",
      "Name: 6, dtype: object\n",
      "(Pdb) match_primary_tumor\n",
      "        entity:sample_id participant_id  \\\n",
      "5  BT1009-Tumor-SM-DB2HZ         BT1009   \n",
      "\n",
      "                              clean_bam_file_capture external_id_validation  \\\n",
      "5  gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...         BT1009_primary   \n",
      "\n",
      "    aggregation_product_name_validation bsp_sample_id_validation  \\\n",
      "5  TSCA Rapid Cancer Detection Panel v2                 SM-DB9J7   \n",
      "\n",
      "  stock_sample_id_validation sample_type picard_aggregation_type_validation  \\\n",
      "5                   SM-DB2HZ       Tumor                                PCR   \n",
      "\n",
      "      processed_subtype_validation source_subtype_validation  \\\n",
      "5  Tissue:Tissue Lysate/Homogenate       Tissue:Fresh Tissue   \n",
      "\n",
      "  squid_sample_id_validation tumor_subtype short_letter_code  \\\n",
      "5             BT1009_primary    Metastatic                TM   \n",
      "\n",
      "                                        bam_filename  \\\n",
      "5  1_BT1009_primary_HYTLGBCXX.1.aligned.duplicate...   \n",
      "\n",
      "                                        bai_filename  \\\n",
      "5  1_BT1009_primary_HYTLGBCXX.1.aligned.duplicate...   \n",
      "\n",
      "                              clean_bai_file_capture tsca_id  \n",
      "5  gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...  TSCA14  \n",
      "(Pdb) match_primary_tumor.sample(n=1)\n",
      "        entity:sample_id participant_id  \\\n",
      "5  BT1009-Tumor-SM-DB2HZ         BT1009   \n",
      "\n",
      "                              clean_bam_file_capture external_id_validation  \\\n",
      "5  gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...         BT1009_primary   \n",
      "\n",
      "    aggregation_product_name_validation bsp_sample_id_validation  \\\n",
      "5  TSCA Rapid Cancer Detection Panel v2                 SM-DB9J7   \n",
      "\n",
      "  stock_sample_id_validation sample_type picard_aggregation_type_validation  \\\n",
      "5                   SM-DB2HZ       Tumor                                PCR   \n",
      "\n",
      "      processed_subtype_validation source_subtype_validation  \\\n",
      "5  Tissue:Tissue Lysate/Homogenate       Tissue:Fresh Tissue   \n",
      "\n",
      "  squid_sample_id_validation tumor_subtype short_letter_code  \\\n",
      "5             BT1009_primary    Metastatic                TM   \n",
      "\n",
      "                                        bam_filename  \\\n",
      "5  1_BT1009_primary_HYTLGBCXX.1.aligned.duplicate...   \n",
      "\n",
      "                                        bai_filename  \\\n",
      "5  1_BT1009_primary_HYTLGBCXX.1.aligned.duplicate...   \n",
      "\n",
      "                              clean_bai_file_capture tsca_id  \n",
      "5  gs://fc-35446f22-ea37-483a-bd6c-5e9fc56851ff/s...  TSCA14  \n",
      "(Pdb) match_primary_tumor['entity:sample_id'].item()\n",
      "'BT1009-Tumor-SM-DB2HZ'\n",
      "(Pdb) match_normal['clean_bam_file_capture'].item()\n",
      "*** ValueError: can only convert an array of size 1 to a Python scalar\n",
      "(Pdb) match_normal['clean_bam_file_capture']\n",
      "Series([], Name: clean_bam_file_capture, dtype: object)\n",
      "(Pdb) exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-5323573d0689>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mwrite_df_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples_with_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsca_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprepare_all_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TSCA18'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/xchip/clf/seq_data/processed_for_fh/tsca18_201704_SN0119223/tsca18_201704_SN0119223.import_samples.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-5323573d0689>\u001b[0m in \u001b[0;36mprepare_all_metadata\u001b[0;34m(tsca_id, path_to_samples_info)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_samples_for_metadata_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_samples_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsca_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoogle_bucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mall_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'paths_to_samples_info.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoogle_bucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mbatch_samples_with_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_matching_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwrite_df_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_samples_with_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsca_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-c4df0196f451>\u001b[0m in \u001b[0;36madd_matching_samples\u001b[0;34m(all_samples, batch_samples)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'match_primary_tumor_sample_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity:sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'match_primary_tumor_bam_file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_bam_file_capture'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-c4df0196f451>\u001b[0m in \u001b[0;36madd_matching_samples\u001b[0;34m(all_samples, batch_samples)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'match_primary_tumor_sample_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entity:sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mbatch_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'match_primary_tumor_bam_file'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_primary_tumor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_bam_file_capture'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "google_bucket_id = \"fc-35446f22-ea37-483a-bd6c-5e9fc56851ff\"\n",
    "def prepare_all_metadata(tsca_id, path_to_samples_info):    \n",
    "    patients_for_metadata_import(path_to_samples_info, tsca_id)\n",
    "    batch_sample_set_for_metadata_import(path_to_samples_info, tsca_id)\n",
    "    batch_samples = batch_samples_for_metadata_import(path_to_samples_info, tsca_id, google_bucket_id)\n",
    "    all_samples = compile_samples('paths_to_samples_info.xlsx', google_bucket_id)\n",
    "    batch_samples_with_normal = add_matching_samples(all_samples, batch_samples)\n",
    "    write_df_to_csv(batch_samples_with_normal, tsca_id)\n",
    "    \n",
    "prepare_all_metadata('TSCA18', '/xchip/clf/seq_data/processed_for_fh/tsca18_201704_SN0119223/tsca18_201704_SN0119223.import_samples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating panel of 20 normals\n"
     ]
    }
   ],
   "source": [
    "### Create Cumulative PoN\n",
    "paths = [\"/xchip/clf/seq_data/processed_for_fh/tsca20_201707_SN0125362/tsca20_201707_SN0125362.import_samples.txt\", \\\n",
    "        \"/xchip/clf/seq_data/processed_for_fh/tsca19_201706_SN0122601/tsca19_201706_SN0122601.import_samples.txt\"]\n",
    "panel_of_normals_for_metadata_import(paths, -1, 'CumPoN_1920')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create Batch PoN\n",
    "paths = [\"/xchip/clf/seq_data/processed_for_fh/tsca19_201706_SN0122601/tsca19_201706_SN0122601.import_samples.txt\"]\n",
    "panel_of_normals_for_metadata_import(paths, -1, 'TSCA19_PoN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Adding match normals to every tumor sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find match normals, primary tumor tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = compile_samples('paths_to_samples_info.xlsx', google_bucket_id)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity:sample_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clean_bam_file_capture</th>\n",
       "      <th>external_id_validation</th>\n",
       "      <th>aggregation_product_name_validation</th>\n",
       "      <th>bsp_sample_id_validation</th>\n",
       "      <th>stock_sample_id_validation</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>picard_aggregation_type_validation</th>\n",
       "      <th>processed_subtype_validation</th>\n",
       "      <th>source_subtype_validation</th>\n",
       "      <th>squid_sample_id_validation</th>\n",
       "      <th>tumor_subtype</th>\n",
       "      <th>short_letter_code</th>\n",
       "      <th>bam_filename</th>\n",
       "      <th>bai_filename</th>\n",
       "      <th>clean_bai_file_capture</th>\n",
       "      <th>tsca_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [entity:sample_id, participant_id, clean_bam_file_capture, external_id_validation, aggregation_product_name_validation, bsp_sample_id_validation, stock_sample_id_validation, sample_type, picard_aggregation_type_validation, processed_subtype_validation, source_subtype_validation, squid_sample_id_validation, tumor_subtype, short_letter_code, bam_filename, bai_filename, clean_bai_file_capture, tsca_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples[all_samples['entity:sample_id'] == 'BT1009-Tumor-SM-DB2H' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
