{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from firecloud import api as firecloud_api\n",
    "import glob\n",
    "import fc_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameters\n",
    "namespace = \"nci-mimoun-bi-org\"\n",
    "workspace = \"CCLF_TSCA\"\n",
    "paths_to_samples_info = \"paths_to_batches_info.xlsx\"\n",
    "google_bucket_id = \"fc-35446f22-ea37-483a-bd6c-5e9fc56851ff\"\n",
    "batches_info = pd.read_excel(paths_to_samples_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete unnecessary attributes in samples\n",
    "attrs = [\"annotate_variants_vcf\", \"annotate_variants_vcf_index\", \"oncotated_maf\", \"mutect2_vcf_index\", \"match_normal_oncotated_maf\", \"gnomad_vcf\", \"merged_vcfs\", \"match_primary_tumor_bam_file\"]\n",
    "for idx, row in all_samples.iterrows():\n",
    "    fc_interface.delete_entity_attributes(namespace, workspace, \"sample\", row['entity:sample_id'], attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete method repostory\n",
    "firecloud_api.delete_repository_method('tsca', 'CreatePoN', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete method repository\n",
    "firecloud_api.delete_repository_method('tsca', 'Mutect2_for_Normal', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete multiple method repositories\n",
    "for i in range(10, 23):\n",
    "    firecloud_api.delete_repository_method('tsca', 'CreatePoN', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete method config\n",
    "firecloud_api.delete_workspace_config(namespace, workspace, \"tsca\", \"Mutect2_for_Normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pair creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Create pairs\n",
    "all_samples = fc_interface.get_samples_multiple_batches(paths_to_samples_info, google_bucket_id)\n",
    "pairs_list = fc_interface.create_pairs_list(all_samples)\n",
    "blacklist = [\"DW039-Tumor-SM-DB2IF\"]\n",
    "clean_pairs_list = pairs_list[ ~pairs_list['case_sample_id'].isin(blacklist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Upload pairs\n",
    "res = fc_interface.upload_pairs(namespace, workspace, clean_pairs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# ### Delete unnecessary attributes in pairs\n",
    "# ### NOT WOKING\n",
    "# all_samples = fc_interface.get_samples_multiple_batches(paths_to_samples_info, google_bucket_id)\n",
    "# pairs_list = fc_interface.create_pairs_list(all_samples)\n",
    "# attrs = [\"__annotate_variants_vcf\", \"__annotate_variants_vcf_index\", \\\n",
    "#          \"__scattered_intervals\", \"__tmp_mutect_vcf2\", \"_tmp_mutect_vcf_index2\", \\\n",
    "#          \"__tmp_mutect_vcf2\", \"_tmp_mutect_vcf_index2\"]\n",
    "# for idx, row in pairs_list.iterrows():\n",
    "#     fc_interface.delete_entity_attributes(namespace, workspace, \"pair\", row['entity:pair_id'], attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Upload metadata for given batch\n",
    "fc_interface.update_batch_metadata('TSCA21', \\\n",
    "                                  '/xchip/clf/seq_data/processed_for_fh/tsca21_201708_SN0128552/tsca21_201708_SN0128552.import_samples.txt', \\\n",
    "                                      paths_to_samples_info, \\\n",
    "                                        namespace, workspace, google_bucket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete sample_set\n",
    "fc_interface.delete_sample_set(namespace, workspace, 'TSCA1213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### All paths to batch info\n",
    "# pd.read_excel('paths_to_batches_info.xlsx').path_to_samples_info.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Create cumulative PoN (all batches)\n",
    "batches_info = pd.read_excel(paths_to_samples_info)\n",
    "PoN = fc_interface.create_panel_of_normals(batches_info.path_to_samples_info.tolist(), -1, 'Cum_PoN_21_all')\n",
    "fc_interface.upload_pon(PoN, 'CumPoN21', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Create PoN from normals of only one batch (no samples from other batches)\n",
    "batches_info = pd.read_excel(paths_to_samples_info)\n",
    "tsca21_path = batches_info.path_to_samples_info.tolist()[-1]\n",
    "PoN = fc_interface.create_panel_of_normals([tsca21_path], -1, 'PoN_TSCA21_Normals')\n",
    "fc_interface.upload_pon(PoN, 'PoN_TSCA21_Normals', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete pair set\n",
    "fc_interface.delete_pair_set(namespace, workspace, 'TSCA1213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete sample set\n",
    "fc_interface.delete_sample_set(namespace, workspace, 'TSCA1213')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Download method configs\n",
    "fc_interface.download_method_configs(namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Upload pairsets\n",
    "tn_pairsets, tp_pairsets = fc_interface.create_pairsets(all_samples, clean_pairs_list)\n",
    "fc_interface.upload_pairsets(namespace, workspace, tn_pairsets, \"TN\")\n",
    "fc_interface.upload_pairsets(namespace, workspace, tp_pairsets, \"TP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete all pairs\n",
    "for idx, row in clean_pairs_list.iterrows():\n",
    "    res = fc_interface.delete_pair(namespace, workspace, row['entity:pair_id'])\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "all_samples = fc_interface.get_samples_multiple_batches(paths_to_samples_info, google_bucket_id)\n",
    "pairs_list = fc_interface.create_pairs_list(all_samples)\n",
    "blacklist = [\"DW039-Tumor-SM-DB2IF\"]\n",
    "clean_pairs_list = pairs_list[ ~pairs_list['case_sample_id'].isin(blacklist)]\n",
    "\n",
    "### Update pair attributes\n",
    "update_pair_attrs(namespace, workspace, clean_pairs_list, attrs=['control_sample_tsca_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Create PoN from all normals\n",
    "batches_info = pd.read_excel(paths_to_samples_info)\n",
    "all_paths = batches_info.path_to_samples_info.tolist()\n",
    "PoN = fc_interface.create_panel_of_normals(all_paths, -1, 'Cum_PoN_21_all')\n",
    "fc_interface.upload_pon(PoN, 'Cum_PoN_21_all', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Create PoN with normals from batch + other normals\n",
    "batches_info = pd.read_excel(paths_to_samples_info)\n",
    "all_paths = batches_info.path_to_samples_info.tolist()\n",
    "# PoN = fc_interface.create_panel_of_normals(all_paths, -1, 'Cum_PoN_21_all')\n",
    "# fc_interface.upload_pon(PoN, 'Cum_PoN_21_all', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_id = 'TSCA21'\n",
    "# batch_path = batches_info.loc[batches_info.tsca_id==batch_id, 'path_to_samples_info'].item()\n",
    "# pd.read_table(batch_path)\n",
    "# batch_id, paths, N, name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Delete all cohorts\n",
    "cohort_metadata = pd.read_table('cohort_files/cohort_names_dictionary.txt', header=None, names=['name', 'code'])\n",
    "cohort_codes = cohort_metadata.code.tolist()\n",
    "for c in cohort_codes:\n",
    "    fc_interface.delete_sample_set(namespace, workspace, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve samples before export to FC\n",
    "tsca21 = \\\n",
    "    fc_interface.\\\n",
    "        prepare_batch_samples_for_metadata_export('/xchip/clf/seq_data/processed_for_fh/tsca21_201708_SN0128552/tsca21_201708_SN0128552.import_samples.txt', \\\n",
    "                            'TSCA21', google_bucket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Update WDLs\n",
    "fc_interface.download_remote_wdls(namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Prepare cohorts for export to FC\n",
    "cohorts = fc_interface.prepare_cohorts_for_metadata_export(paths_to_batches_info, google_bucket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# # Delete cohorts\n",
    "# cohort_codes = pd.read_table('cohort_files/cohort_names_dictionary.txt', header=None)\n",
    "# for coh_code in cohort_codes.loc[:, 1].tolist():\n",
    "#     res = fc_interface.delete_sample_set(namespace, workspace, coh_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 Participants in this batch\n",
      "95 Samples in this batch\n"
     ]
    }
   ],
   "source": [
    "# ### Upload metadata for given batch\n",
    "# fc_interface.update_batch_metadata('TSCA21', \\\n",
    "#                                   '/xchip/clf/seq_data/processed_for_fh/tsca21_201708_SN0128552/tsca21_201708_SN0128552.import_samples.txt', \\\n",
    "#                                       paths_to_samples_info, \\\n",
    "#                                         namespace, workspace, google_bucket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Export metadata\n",
    "(r1, r2, r3, r4, r5, r6) = fc_interface.export_batch_metadata_to_fc('TSCA21', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Cohorts\n",
    "cohorts = fc_interface.prepare_cohorts_for_metadata_export(paths_to_batches_info, google_bucket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Create panel of normals from batch\n",
    "pon = fc_interface.create_panel_of_normals_from_batch(batch_id, paths_to_samples_info, N=20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Create panel of normals from batch\n",
    "for i, row in batches_info.iterrows():\n",
    "    pon, name = fc_interface.create_panel_of_normals_from_batch(row['tsca_id'], paths_to_samples_info, N=20)\n",
    "    fc_interface.upload_pon(pon, name, namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve samples before export to FC\n",
    "tsca21 = \\\n",
    "    fc_interface.\\\n",
    "        prepare_batch_samples_for_metadata_export('/xchip/clf/seq_data/processed_for_fh/tsca21_201708_SN0128552/tsca21_201708_SN0128552.import_samples.txt', \\\n",
    "                            'TSCA21', google_bucket_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Prepare cohorts for export to FC\n",
    "cohorts = fc_interface.\\\n",
    "            prepare_cohorts_for_metadata_export(paths_to_samples_info, google_bucket_id, \\\n",
    "                                               blacklist=[\"CCLF_AA1012-Tumor-SM-F67DF\"])\n",
    "\n",
    "cohorts_sample_set_metadata = \"cohort_files/fc_upload_sample_set_cohorts.txt\"\n",
    "res = fc_interface.upload_entities_from_tsv(namespace, workspace, cohorts_sample_set_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Export metadata\n",
    "(r1, r2, r3, r4, r5, r6) = fc_interface.export_batch_metadata_to_fc('TSCA21', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "### Cohort of all tumors\n",
    "res = fc_interface.upload_cohort_all_tumors(paths_to_samples_info, google_bucket_id, \\\n",
    "                                      'Cum_Tumors_22_all', namespace, workspace, ['DW039-Tumor-SM-DB2IF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fc_interface.merge_walkupseq_files(paths_to_samples_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refined: New Batch Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "tsca_id = \"TSCA22\"\n",
    "tsca_num = \"22\"\n",
    "blacklist = [\"DW039-Tumor-SM-DB2IF\"]\n",
    "path_to_batch_samples_info = batches_info.loc[batches_info.tsca_id==tsca_id, 'path_to_samples_info'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### ALL SAMPLES\n",
    "## Prepare\n",
    "# fc_interface.prepare_patients_for_metadata_export(path_to_batch_samples_info, tsca_id)\n",
    "# fc_interface.prepare_batch_sample_set_for_metadata_export(path_to_batch_samples_info, tsca_id)\n",
    "# fc_interface.prepare_batch_samples_for_metadata_export(path_to_batch_samples_info, tsca_id, google_bucket_id)\n",
    "\n",
    "## Export\n",
    "# fc_interface.export_batch_metadata_to_fc(tsca_id, namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### PANEL OF NORMALS BATCH\n",
    "## Prepare \n",
    "# pon, name = fc_interface.create_panel_of_normals_from_batch(tsca_id, paths_to_samples_info, N=20)\n",
    "\n",
    "# Export\n",
    "# fc_interface.upload_pon(pon, name, namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating panel of 163 normals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### PANEL OF NORMALS CUMULATIVE\n",
    "## Prepare\n",
    "# batches_info = pd.read_excel(paths_to_samples_info)\n",
    "# PoN = fc_interface.create_panel_of_normals(batches_info.path_to_samples_info.tolist(), -1, 'Cum_PoN_22_all')\n",
    "\n",
    "# Export\n",
    "# fc_interface.upload_pon(PoN, 'Cum_PoN_22_all', namespace, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### COHORT SAMPLE SETS\n",
    "## Prepare\n",
    "# cohorts = fc_interface.prepare_cohorts_for_metadata_export(paths_to_samples_info, \\\n",
    "#                                                            google_bucket_id, blacklist, tsca_id, \\\n",
    "#                                                           namespace, workspace)\n",
    "\n",
    "# ## Export\n",
    "# res = fc_interface.upload_cohorts(namespace, workspace, tsca_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/xchip/clf/seq_data/processed_for_fh/tsca1213_201610_SN0106956/tsca1213_201610_SN0106956.import_samples.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-231-76175e74489c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### PAIRS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m## Prepare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_samples_multiple_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_to_samples_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoogle_bucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpairs_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pairs_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mblacklist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"DW039-Tumor-SM-DB2IF\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/production_fc/metadata_exports/fc_interface.py\u001b[0m in \u001b[0;36mget_samples_multiple_batches\u001b[0;34m(paths_to_samples_info, google_bucket_id, sublist)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Make data Firecloud-compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_batch_samples_for_metadata_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_to_samples_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsca_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoogle_bucket_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/production_fc/metadata_exports/fc_interface.py\u001b[0m in \u001b[0;36mprepare_batch_samples_for_metadata_export\u001b[0;34m(path, tsca_id, google_bucket_id)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# export raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;31m# Rename columns to match firecloud requirements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mimoun/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/xchip/clf/seq_data/processed_for_fh/tsca1213_201610_SN0106956/tsca1213_201610_SN0106956.import_samples.txt' does not exist"
     ]
    }
   ],
   "source": [
    "# ### PAIRS\n",
    "# ## Prepare\n",
    "# clean_pair_list = fc_interface.prepare_pairs_for_metadata_exports(paths_to_samples_info, tsca_id, google_bucket_id, blacklist)\n",
    "\n",
    "# ## Export\n",
    "# fc_interface.upload_pairs(namespace, workspace, clean_pairs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ### PAIRSETS\n",
    "# ## Prepare\n",
    "# # all_samples = fc_interface.get_samples_multiple_batches(paths_to_samples_info, google_bucket_id)\n",
    "# tn_pairsets, tp_pairsets = fc_interface.create_pairsets(all_samples, clean_pairs_list)\n",
    "\n",
    "# # ### Upload pairsets\n",
    "# fc_interface.upload_pairsets(namespace, workspace, tn_pairsets, \"TN\")\n",
    "# fc_interface.upload_pairsets(namespace, workspace, tp_pairsets, \"TP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CUMULATIVE COHORT OF ALL SAMPLES\n",
    "res = fc_interface.upload_cohort_all_samples(paths_to_samples_info, google_bucket_id, \\\n",
    "                                            'Cum_22_all', namespace, workspace, blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CUMULATIVE PANEL OF NORMALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve list of samples with corresponding cohort from bsp.broadinstitute.org\n",
    "samples_with_cohort = pd.read_excel('cohort_files/bsp_latest_all_samples_%s.xls'%tsca_id)\n",
    "\n",
    "# All samples, without cohort data\n",
    "all_samples = get_samples_multiple_batches(paths_to_batches_info, google_bucket_id)\n",
    "\n",
    "# Add cohort data to all samples\n",
    "data = pd.merge(all_samples, samples_with_cohort[['Sample ID', 'Collection']], \\\n",
    "                 left_on='bsp_sample_id_validation', \\\n",
    "                 right_on='Sample ID', \\\n",
    "                 how='inner') \\\n",
    "                .drop(['Sample ID'], axis=1)\n",
    "\n",
    "# FC doesn't accept cohort names with non-alphanumeric characters, so use cohort codes instead\n",
    "# Load dictionary of {long cohort name : short cohort code}\n",
    "cohort_formatted_names = pd.read_table('cohort_files/cohort_names_dictionary.txt', \\\n",
    "                                       header=None, names=['Collection', 'cohort_code'])\n",
    "\n",
    "# Add cohort codes to data\n",
    "data = pd.merge(data, cohort_formatted_names, on='Collection', how='outer')\n",
    "\n",
    "# Prepare for FC export format\n",
    "data = data.rename(columns={'cohort_code': 'membership:sample_set_id', 'entity:sample_id': 'sample_id'})\n",
    "data_clean = data[['membership:sample_set_id', 'sample_id']]\n",
    "\n",
    "# Remove blacklist\n",
    "data_clean = data_clean[ ~data_clean['sample_id'].isin(blacklist)]\n",
    "\n",
    "# Samples in new batch\n",
    "samples_new_batch = pd.read_table(\"%s/fc_upload_sample_set_tsca_%s.txt\"%(tsca_id, tsca_id))\n",
    "\n",
    "# Only upload new samples. As of 10/17, Firecloud doesn't filter duplicate entries\n",
    "data_clean = data_clean[ data_clean['sample_id'].isin(samples_new_batch.sample_id.tolist()) ]\n",
    "\n",
    "# Write FC import file \n",
    "data_clean.to_csv('cohort_files/fc_upload_sample_set_cohorts_%s.txt'%tsca_id, index=False, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
